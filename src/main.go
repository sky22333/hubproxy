package main

import (
	"embed"
	"fmt"
	"github.com/gin-gonic/gin"
	"io"
	"net/http"
	"regexp"
	"strconv"
	"strings"
)

//go:embed public/*
var staticFiles embed.FS

// æœåŠ¡åµŒå…¥çš„é™æ€æ–‡ä»¶
func serveEmbedFile(c *gin.Context, filename string) {
	data, err := staticFiles.ReadFile(filename)
	if err != nil {
		c.Status(404)
		return
	}
	contentType := "text/html; charset=utf-8"
	if strings.HasSuffix(filename, ".ico") {
		contentType = "image/x-icon"
	}
	c.Data(200, contentType, data)
}

var (
	exps = []*regexp.Regexp{
		regexp.MustCompile(`^(?:https?://)?github\.com/([^/]+)/([^/]+)/(?:releases|archive)/.*$`),
		regexp.MustCompile(`^(?:https?://)?github\.com/([^/]+)/([^/]+)/(?:blob|raw)/.*$`),
		regexp.MustCompile(`^(?:https?://)?github\.com/([^/]+)/([^/]+)/(?:info|git-).*$`),
		regexp.MustCompile(`^(?:https?://)?raw\.github(?:usercontent|)\.com/([^/]+)/([^/]+)/.+?/.+$`),
		regexp.MustCompile(`^(?:https?://)?gist\.github(?:usercontent|)\.com/([^/]+)/.+?/.+`),
		regexp.MustCompile(`^(?:https?://)?api\.github\.com/repos/([^/]+)/([^/]+)/.*`),
		regexp.MustCompile(`^(?:https?://)?huggingface\.co(?:/spaces)?/([^/]+)/(.+)$`),
		regexp.MustCompile(`^(?:https?://)?cdn-lfs\.hf\.co(?:/spaces)?/([^/]+)/([^/]+)(?:/(.*))?$`),
		regexp.MustCompile(`^(?:https?://)?download\.docker\.com/([^/]+)/.*\.(tgz|zip)$`),
		regexp.MustCompile(`^(?:https?://)?(github|opengraph)\.githubassets\.com/([^/]+)/.+?$`),
	}
	globalLimiter *IPRateLimiter
)

func main() {
	// åŠ è½½é…ç½®
	if err := LoadConfig(); err != nil {
		fmt.Printf("é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		return
	}
	
	// åˆå§‹åŒ–HTTPå®¢æˆ·ç«¯
	initHTTPClients()
	
	// åˆå§‹åŒ–é™æµå™¨
	initLimiter()
	
	// åˆå§‹åŒ–Dockeræµå¼ä»£ç†
	initDockerProxy()

	gin.SetMode(gin.ReleaseMode)
	router := gin.Default()

	// åˆå§‹åŒ–skopeoè·¯ç”±ï¼ˆé™æ€æ–‡ä»¶å’ŒAPIè·¯ç”±ï¼‰
	initSkopeoRoutes(router)
	
	// é™æ€æ–‡ä»¶è·¯ç”±ï¼ˆä½¿ç”¨åµŒå…¥æ–‡ä»¶ï¼‰
	router.GET("/", func(c *gin.Context) {
		serveEmbedFile(c, "public/index.html")
	})
	router.GET("/public/*filepath", func(c *gin.Context) {
		filepath := strings.TrimPrefix(c.Param("filepath"), "/")
		serveEmbedFile(c, "public/"+filepath)
	})
	router.GET("/skopeo.html", func(c *gin.Context) {
		serveEmbedFile(c, "public/skopeo.html")
	})
	router.GET("/search.html", func(c *gin.Context) {
		serveEmbedFile(c, "public/search.html")
	})
	router.GET("/favicon.ico", func(c *gin.Context) {
		serveEmbedFile(c, "public/favicon.ico")
	})

	// æ³¨å†Œdockerhubæœç´¢è·¯ç”±
	RegisterSearchRoute(router)
	
	// æ³¨å†ŒDockerè®¤è¯è·¯ç”±ï¼ˆ/token*ï¼‰
	router.Any("/token", RateLimitMiddleware(globalLimiter), ProxyDockerAuthGin)
	router.Any("/token/*path", RateLimitMiddleware(globalLimiter), ProxyDockerAuthGin)
	
	// æ³¨å†ŒDocker Registryä»£ç†è·¯ç”±
	router.Any("/v2/*path", RateLimitMiddleware(globalLimiter), ProxyDockerRegistryGin)
	

	// æ³¨å†ŒNoRouteå¤„ç†å™¨ï¼Œåº”ç”¨é™æµä¸­é—´ä»¶
	router.NoRoute(RateLimitMiddleware(globalLimiter), handler)

	cfg := GetConfig()
	fmt.Printf("å¯åŠ¨æˆåŠŸï¼Œé¡¹ç›®åœ°å€ï¼šhttps://github.com/sky22333/hubproxy \n")
	
	err := router.Run(fmt.Sprintf("%s:%d", cfg.Server.Host, cfg.Server.Port))
	if err != nil {
		fmt.Printf("å¯åŠ¨æœåŠ¡å¤±è´¥: %v\n", err)
	}
}

func handler(c *gin.Context) {
	rawPath := strings.TrimPrefix(c.Request.URL.RequestURI(), "/")

	for strings.HasPrefix(rawPath, "/") {
		rawPath = strings.TrimPrefix(rawPath, "/")
	}

	if !strings.HasPrefix(rawPath, "http") {
		c.String(http.StatusForbidden, "æ— æ•ˆè¾“å…¥")
		return
	}

	matches := checkURL(rawPath)
	if matches != nil {
		// GitHubä»“åº“è®¿é—®æ§åˆ¶æ£€æŸ¥
		if allowed, reason := GlobalAccessController.CheckGitHubAccess(matches); !allowed {
			// æ„å»ºä»“åº“åç”¨äºæ—¥å¿—
			var repoPath string
			if len(matches) >= 2 {
				username := matches[0]
				repoName := strings.TrimSuffix(matches[1], ".git")
				repoPath = username + "/" + repoName
			}
			fmt.Printf("GitHubä»“åº“ %s è®¿é—®è¢«æ‹’ç»: %s\n", repoPath, reason)
			c.String(http.StatusForbidden, reason)
			return
		}
	} else {
		c.String(http.StatusForbidden, "æ— æ•ˆè¾“å…¥")
		return
	}

	if exps[1].MatchString(rawPath) {
		rawPath = strings.Replace(rawPath, "/blob/", "/raw/", 1)
	}

	proxy(c, rawPath)
}


func proxy(c *gin.Context, u string) {
	proxyWithRedirect(c, u, 0)
}


func proxyWithRedirect(c *gin.Context, u string, redirectCount int) {
	// é™åˆ¶æœ€å¤§é‡å®šå‘æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™é€’å½’
	const maxRedirects = 20
	if redirectCount > maxRedirects {
		c.String(http.StatusLoopDetected, "é‡å®šå‘æ¬¡æ•°è¿‡å¤šï¼Œå¯èƒ½å­˜åœ¨å¾ªç¯é‡å®šå‘")
		return
	}
	req, err := http.NewRequest(c.Request.Method, u, c.Request.Body)
	if err != nil {
		c.String(http.StatusInternalServerError, fmt.Sprintf("server error %v", err))
		return
	}

	for key, values := range c.Request.Header {
		for _, value := range values {
			req.Header.Add(key, value)
		}
	}
	req.Header.Del("Host")

	resp, err := GetGlobalHTTPClient().Do(req)
	if err != nil {
		c.String(http.StatusInternalServerError, fmt.Sprintf("server error %v", err))
		return
	}
	defer func() {
		if err := resp.Body.Close(); err != nil {
			fmt.Printf("å…³é—­å“åº”ä½“å¤±è´¥: %v\n", err)
		}
	}()

	// æ£€æŸ¥æ–‡ä»¶å¤§å°é™åˆ¶
	cfg := GetConfig()
	if contentLength := resp.Header.Get("Content-Length"); contentLength != "" {
		if size, err := strconv.ParseInt(contentLength, 10, 64); err == nil && size > cfg.Server.FileSize {
			c.String(http.StatusRequestEntityTooLarge, 
				fmt.Sprintf("æ–‡ä»¶è¿‡å¤§ï¼Œé™åˆ¶å¤§å°: %d MB", cfg.Server.FileSize/(1024*1024)))
			return
		}
	}

	// æ¸…ç†å®‰å…¨ç›¸å…³çš„å¤´
	resp.Header.Del("Content-Security-Policy")
	resp.Header.Del("Referrer-Policy")
	resp.Header.Del("Strict-Transport-Security")
	
	// æ™ºèƒ½å¤„ç†ç³»ç»Ÿ - è‡ªåŠ¨è¯†åˆ«éœ€è¦åŠ é€Ÿçš„å†…å®¹
	// è·å–çœŸå®åŸŸå
	realHost := c.Request.Header.Get("X-Forwarded-Host")
	if realHost == "" {
		realHost = c.Request.Host
	}
	// å¦‚æœåŸŸåä¸­æ²¡æœ‰åè®®å‰ç¼€ï¼Œæ·»åŠ https://
	if !strings.HasPrefix(realHost, "http://") && !strings.HasPrefix(realHost, "https://") {
		realHost = "https://" + realHost
	}

	// ğŸš€ é«˜æ€§èƒ½é¢„ç­›é€‰ï¼šä»…å¯¹.shæ–‡ä»¶è¿›è¡Œæ™ºèƒ½å¤„ç†
	if strings.HasSuffix(strings.ToLower(u), ".sh") {
		// æ£€æŸ¥æ˜¯å¦ä¸ºgzipå‹ç¼©å†…å®¹
		isGzipCompressed := resp.Header.Get("Content-Encoding") == "gzip"
		
		// ä»…å¯¹shellè„šæœ¬ä½¿ç”¨æ™ºèƒ½å¤„ç†å™¨
		processedBody, processedSize, err := ProcessSmart(resp.Body, isGzipCompressed, realHost)
		if err != nil {
			// ä¼˜é›…é™çº§ - å¤„ç†å¤±è´¥æ—¶ä½¿ç”¨ç›´æ¥ä»£ç†æ¨¡å¼
			fmt.Printf("æ™ºèƒ½å¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°ç›´æ¥ä»£ç†: %v\n", err)
			processedBody = resp.Body
			processedSize = 0
		}

		// æ™ºèƒ½è®¾ç½®å“åº”å¤´
		if processedSize > 0 {
			// å†…å®¹è¢«å¤„ç†è¿‡ï¼Œæ¸…ç†å‹ç¼©ç›¸å…³å¤´ï¼Œä½¿ç”¨chunkedä¼ è¾“
			resp.Header.Del("Content-Length")
			resp.Header.Del("Content-Encoding")
			resp.Header.Set("Transfer-Encoding", "chunked")
		}

		// å¤åˆ¶å…¶ä»–å“åº”å¤´
		for key, values := range resp.Header {
			for _, value := range values {
				c.Header(key, value)
			}
		}

		if location := resp.Header.Get("Location"); location != "" {
			if checkURL(location) != nil {
				c.Header("Location", "/"+location)
			} else {
				proxyWithRedirect(c, location, redirectCount+1)
				return
			}
		}

		c.Status(resp.StatusCode)

		// è¾“å‡ºå¤„ç†åçš„å†…å®¹
		if _, err := io.Copy(c.Writer, processedBody); err != nil {
			return
		}
	} else {
		// ğŸ”¥ é.shæ–‡ä»¶ï¼šç›´æ¥é«˜æ€§èƒ½æµå¼ä»£ç†ï¼Œé›¶å†…å­˜æ¶ˆè€—
		// å¤åˆ¶æ‰€æœ‰å“åº”å¤´
		for key, values := range resp.Header {
			for _, value := range values {
				c.Header(key, value)
			}
		}

		// å¤„ç†é‡å®šå‘
		if location := resp.Header.Get("Location"); location != "" {
			if checkURL(location) != nil {
				c.Header("Location", "/"+location)
			} else {
				proxyWithRedirect(c, location, redirectCount+1)
				return
			}
		}

		c.Status(resp.StatusCode)

		// ç›´æ¥æµå¼è½¬å‘ï¼Œé›¶å†…å­˜æ‹·è´
		if _, err := io.Copy(c.Writer, resp.Body); err != nil {
			fmt.Printf("ç›´æ¥ä»£ç†å¤±è´¥: %v\n", err)
		}
	}
}

func checkURL(u string) []string {
	for _, exp := range exps {
		if matches := exp.FindStringSubmatch(u); matches != nil {
			return matches[1:]
		}
	}
	return nil
}
